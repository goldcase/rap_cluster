{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from random import shuffle\n",
    "\n",
    "import os, cPickle\n",
    "\n",
    "PROCESSED_DATA_DIR = \"processed_data\"\n",
    "NUM_CLUSTERS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K Means attempts to cluster data by splitting data into groups of equal variance.\n",
    "# Requires number of clusters to be specified.\n",
    "# Centroid: mean of cluster.\n",
    "# Aims to choose centroids that minimize the inertia, or intra-cluster sum of squared distance from the mean.\n",
    "\n",
    "# Drawbacks\n",
    "# Note that inertia makes the assumption that clusters are convex and isotropic (identical in all directions).\n",
    "# Inertia responds poorly to elongated clusters.\n",
    "# Inertia is not a normalized metric. PCA can reduce the inflation of Euclidean distances that occur with high-dimensional spaces.\n",
    "# 1. Choose initial centroid, k samples from the dataset.\n",
    "# 2. Assign each sample to its nearest centroid\n",
    "# 3. Create new centroids by taking the mean value of all the samples assigned to each previous centroid.\n",
    "# K means will always converge, but this might be a local minimum, heavily dependent on centroid initialization.\n",
    "# As such, centroid initialization is done several times.\n",
    "\n",
    "# In other words, k-means is EM w/small, all-equal diagonal covar matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    ret = []\n",
    "    file_paths = []\n",
    "    vec = DictVectorizer()\n",
    "\n",
    "    dirs_list        = next(os.walk(PROCESSED_DATA_DIR))[1]\n",
    "    joined_dirs_list = [os.path.join(PROCESSED_DATA_DIR, d) for d in dirs_list]\n",
    "\n",
    "    for subdir in joined_dirs_list:\n",
    "        # Walk files in every subdirectory.\n",
    "        for root, dirs, files in os.walk(subdir):\n",
    "            for file_item in files:\n",
    "                file_path = os.path.join(subdir, file_item)\n",
    "\n",
    "                # Read file and vectorize lyrics.\n",
    "                with open(file_path) as f:\n",
    "                    ret.append(cPickle.load(f))\n",
    "                \n",
    "                file_paths.append(file_path)\n",
    "\n",
    "    return vec.fit_transform(ret).toarray(), file_paths, ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data, file_paths, freqs = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert(len(data) == len(file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_jobs = -1 means that KMeans should be as parallel as possible.\n",
    "estimator = KMeans(n_clusters=NUM_CLUSTERS, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, ..., 8, 8, 8], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit_predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "song_labels = estimator.labels_\n",
    "songs_by_label = [[] for i in xrange(NUM_CLUSTERS)]\n",
    "\n",
    "for i in xrange(len(data)):\n",
    "    songs_by_label[song_labels[i]].append(file_paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 33\n",
      "1: 309\n",
      "2: 38\n",
      "3: 265\n",
      "4: 514\n",
      "5: 10\n",
      "6: 5\n",
      "7: 9\n",
      "8: 1032\n",
      "9: 1\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(NUM_CLUSTERS):\n",
    "    print \"{}: {}\".format(i, len(songs_by_label[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = [i for i in xrange(len(songs_by_label))]\n",
    "for i in xrange(len(songs_by_label)):\n",
    "    temp = {}\n",
    "    for song_name in songs_by_label[i]:\n",
    "        idx = file_paths.index(song_name)\n",
    "        song_freq = freqs[idx]\n",
    "        for k, v in song_freq.iteritems():\n",
    "            if k in temp:\n",
    "                temp[k] += v\n",
    "            else:\n",
    "                temp[k] = v\n",
    "    words[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_top_words = [sorted(d, key=d.get, reverse=True) for d in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'like', u'ya', u'im', u'know', u'got', u'me', u'aint', u'get', u'dont', u'na', u'nigga', u'it', u'let', u'back', u'cause', u'yeah', u'go', u'yall', u'bitch', u'yo', u'head', u'tell', u'see', u'gon', u'shit', u'say', u'wan', u'lyrics', u'oh', u'that']\n",
      "[u'im', u'like', u'get', u'got', u'dont', u'know', u'cause', u'me', u'aint', u'shit', u'back', u'lyrics', u'nigga', u'see', u'one', u'na', u'make', u'it', u'fuck', u'man', u'go', u'cant', u'em', u'bitch', u'thats', u'say', u'yeah', u'take', u'come', u'time']\n",
      "[u'love', u'la', u'yeah', u'me', u'like', u'know', u'one', u'im', u'got', u'now', u'dont', u'right', u'get', u'would', u'see', u'wa', u'thats', u'lyrics', u'hood', u'never', u'go', u'cant', u'girls', u'say', u'give', u'make', u'momma', u'back', u'aint', u'you']\n",
      "[u'nigga', u'im', u'get', u'shit', u'got', u'like', u'dont', u'fuck', u'niggas', u'aint', u'bitch', u'know', u'cause', u'ya', u'ass', u'me', u'niggaz', u'see', u'yo', u'lyrics', u'back', u'na', u'thats', u'money', u'em', u'man', u'it', u'yeah', u'go', u'one']\n",
      "[u'got', u'like', u'get', u'im', u'dont', u'know', u'aint', u'na', u'shit', u'me', u'see', u'cause', u'go', u'lyrics', u'back', u'man', u'ya', u'nigga', u'come', u'make', u'one', u'yo', u'wan', u'thats', u'gon', u'say', u'ta', u'cant', u'time', u'em']\n",
      "[u'get', u'money', u'got', u'im', u'like', u'right', u'yeah', u'lit', u'lets', u'mind', u'hot', u'lifted', u'crazy', u'me', u'nigga', u'go', u'shit', u'lil', u'new', u'aint', u'stupid', u'one', u'hit', u'man', u'home', u'ta', u'need', u'lyrics', u'liquor', u'baby']\n",
      "[u'na', u'wan', u'woof', u'back', u'dont', u'mothafucker', u'diamond', u'im', u'make', u'hold', u'get', u'like', u'got', u'gangsta', u'yeah', u'cant', u'nigga', u'alright', u'ya', u'top', u'say', u'know', u'bowwowwowyippieyoyippieyay', u'scene', u'diggin', u'lean', u'sunroof', u'let', u'good', u'ill']\n",
      "[u'go', u'hard', u'jingalin', u'low', u'like', u'baby', u'brooklyn', u'head', u'dumb', u'girls', u'got', u'wild', u'shit', u'im', u'tell', u'know', u'em', u'get', u'is', u'give', u'make', u'pole', u'back', u'gogogo', u'jiggle', u'it', u'sliding', u'na', u'lyrics', u'three']\n",
      "[u'im', u'like', u'got', u'get', u'lyrics', u'know', u'dont', u'aint', u'nigga', u'shit', u'cause', u'me', u'back', u'see', u'it', u'one', u'never', u'man', u'go', u'thats', u'make', u'na', u'fuck', u'yeah', u'say', u'time', u'ya', u'cant', u'come', u'love']\n",
      "[u'one', u'wan', u'na', u'yeah', u'game', u'play', u'baby', u'got', u'im', u'better', u'ya', u'aint', u'never', u'let', u'could', u'seen', u'lyrics', u'find', u'bangle', u'lets', u'get', u'watch', u'know', u'like', u'side', u'hard', u'begun', u'girl', u'out', u'looking']\n"
     ]
    }
   ],
   "source": [
    "num_select = 30\n",
    "for cluster in sorted_top_words:\n",
    "    print cluster[0:num_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.30104261e-18   8.67361738e-19   3.25260652e-19 ...,   1.62630326e-19\n",
      "    1.62630326e-19   6.50521303e-19]\n",
      " [  6.47249191e-03   3.23624595e-03  -6.72205347e-18 ...,  -3.36102673e-18\n",
      "   -3.36102673e-18  -1.34441069e-17]\n",
      " [  1.30104261e-18   8.67361738e-19   3.25260652e-19 ...,   1.62630326e-19\n",
      "    1.62630326e-19   6.50521303e-19]\n",
      " ..., \n",
      " [  4.33680869e-19   0.00000000e+00   1.08420217e-19 ...,   5.42101086e-20\n",
      "    5.42101086e-20   2.16840434e-19]\n",
      " [  1.93798450e-03  -1.51788304e-17   9.68992248e-04 ...,  -5.47522097e-18\n",
      "    9.68992248e-04   3.87596899e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Verify center clusters are around 25 and 10.\n",
    "print(estimator.cluster_centers_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
